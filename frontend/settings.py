import streamlit as st
import os
import requests
import time
import json


# ========================== é»˜è®¤é…ç½® ==========================
DEFAULT_CONFIG = {
    "FINNHUB_API_KEY": "",
    "TAVILY_API_KEY": "",
    "LANGSMITH_API_KEY": "",
    "API_BASE": "http://127.0.0.1:8000",
    "llm_provider": "ChatGPT(Openai)",
    "deep_think_llm": "gpt-4o",  # ç”¨äºå¤æ‚æ¨ç†å’Œæœ€ç»ˆå†³ç­–çš„å¼ºå¤§æ¨¡å‹ã€‚
    "quick_think_llm": "gpt-4o-mini",  # ç”¨äºæ•°æ®å¤„ç†å’Œåˆæ­¥åˆ†æçš„å¿«é€Ÿã€ä½æˆæœ¬æ¨¡å‹ã€‚
    "backend_url": "https://api.openai.com/v1",
    "proxy_enabled": False,
    "proxy_host": "127.0.0.1",
    "proxy_port": "7890",
    "max_debate_rounds": 2,
    "max_risk_discuss_rounds": 1,
    "max_recur_limit": 100,
    "online_tools": True,
    "prompts": {
        "bull": "æ‚¨æ˜¯ä¸€ä½å¤šå¤´åˆ†æå¸ˆã€‚æ‚¨çš„ç›®æ ‡æ˜¯è®ºè¯æŠ•èµ„è¯¥è‚¡ç¥¨çš„åˆç†æ€§ã€‚è¯·é‡ç‚¹å…³æ³¨å¢é•¿æ½œåŠ›ã€ç«äº‰ä¼˜åŠ¿ä»¥åŠæŠ¥å‘Šä¸­çš„ç§¯ææŒ‡æ ‡ã€‚æœ‰æ•ˆåé©³çœ‹è·Œåˆ†æå¸ˆçš„è®ºç‚¹ã€‚",
        "bear": "æ‚¨æ˜¯ä¸€ä½ç©ºå¤´åˆ†æå¸ˆã€‚æ‚¨çš„ç›®æ ‡æ˜¯è®ºè¯æŠ•èµ„è¯¥è‚¡ç¥¨çš„ä¸åˆç†æ€§ã€‚è¯·é‡ç‚¹å…³æ³¨é£é™©ã€æŒ‘æˆ˜ä»¥åŠè´Ÿé¢æŒ‡æ ‡ã€‚æœ‰æ•ˆåé©³çœ‹æ¶¨åˆ†æå¸ˆçš„è®ºç‚¹ã€‚",
        "risky": "æ‚¨æ˜¯å†’é™©å‹é£é™©åˆ†æå¸ˆã€‚æ‚¨ä¸»å¼ é«˜å›æŠ¥æœºä¼šå’Œå¤§èƒ†ç­–ç•¥ã€‚",
        "safe": "æ‚¨æ˜¯ç¨³å¥å‹é£é™©åˆ†æå¸ˆã€‚æ‚¨ä¼˜å…ˆè€ƒè™‘èµ„æœ¬ä¿å€¼å’Œæœ€å°åŒ–æ³¢åŠ¨æ€§ã€‚",
        "neutral": "æ‚¨æ˜¯å¹³è¡¡å‹é£é™©åˆ†æå¸ˆã€‚æ‚¨æä¾›å¹³è¡¡çš„è§†è§’ï¼Œæƒè¡¡æ”¶ç›Šå’Œé£é™©ã€‚",
        "market_analyst": "æ‚¨æ˜¯ä¸€ä½ä¸“é—¨åˆ†æé‡‘èå¸‚åœºçš„äº¤æ˜“åŠ©ç†ã€‚æ‚¨çš„èŒè´£æ˜¯é€‰æ‹©æœ€ç›¸å…³çš„æŠ€æœ¯æŒ‡æ ‡æ¥åˆ†æè‚¡ç¥¨çš„ä»·æ ¼èµ°åŠ¿ã€åŠ¨é‡å’Œæ³¢åŠ¨æ€§ã€‚æ‚¨å¿…é¡»ä½¿ç”¨å·¥å…·è·å–å†å²æ•°æ®ï¼Œç„¶åç”Ÿæˆä¸€ä»½åŒ…å«åˆ†æç»“æœçš„æŠ¥å‘Šï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªæ±‡æ€»è¡¨ã€‚",
        "social_analyst": "æ‚¨æ˜¯ä¸€åç¤¾äº¤åª’ä½“åˆ†æå¸ˆã€‚æ‚¨çš„å·¥ä½œæ˜¯åˆ†æè¿‡å»ä¸€å‘¨å†…ç‰¹å®šå…¬å¸çš„ç¤¾äº¤åª’ä½“å¸–å­å’Œå…¬ä¼—æƒ…ç»ªã€‚ä½¿ç”¨æ‚¨çš„å·¥å…·æŸ¥æ‰¾ç›¸å…³è®¨è®ºï¼Œå¹¶æ’°å†™ä¸€ä»½å…¨é¢çš„æŠ¥å‘Šï¼Œè¯¦ç»†è¯´æ˜æ‚¨çš„åˆ†æã€è§è§£ä»¥åŠå¯¹äº¤æ˜“è€…çš„å½±å“ï¼ŒåŒ…æ‹¬ä¸€ä»½æ±‡æ€»è¡¨ã€‚",
        "news_analyst": "æ‚¨æ˜¯ä¸€åæ–°é—»ç ”ç©¶å‘˜ï¼Œè´Ÿè´£åˆ†æè¿‡å»ä¸€å‘¨çš„æœ€æ–°æ–°é—»å’Œè¶‹åŠ¿ã€‚è¯·æ’°å†™ä¸€ä»½å…³äºå½“å‰ä¸–ç•Œå½¢åŠ¿çš„ç»¼åˆæŠ¥å‘Šï¼Œå†…å®¹éœ€ä¸äº¤æ˜“å’Œå®è§‚ç»æµç›¸å…³ã€‚è¯·ä½¿ç”¨æ‚¨çš„å·¥å…·æä¾›å…¨é¢ã€è¯¦ç»†çš„åˆ†æï¼ŒåŒ…æ‹¬æ±‡æ€»è¡¨ã€‚",
        "fundamentals_analyst": "æ‚¨æ˜¯ä¸€åç ”ç©¶å‘˜ï¼Œæ­£åœ¨åˆ†æå…¬å¸çš„åŸºæœ¬é¢ä¿¡æ¯ã€‚è¯·æ’°å†™ä¸€ä»½å…³äºå…¬å¸è´¢åŠ¡çŠ¶å†µã€å†…éƒ¨äººå£«æƒ…ç»ªå’Œäº¤æ˜“æƒ…å†µçš„ç»¼åˆæŠ¥å‘Šï¼Œä»¥å…¨é¢äº†è§£å…¶åŸºæœ¬é¢çŠ¶å†µï¼Œå¹¶é™„ä¸Šæ±‡æ€»è¡¨ã€‚"
    }
}

CONFIG_FILE = "config_user.json"


# ========================== é…ç½®åŠ è½½ä¸ä¿å­˜ ==========================
def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            # åˆå¹¶é»˜è®¤å€¼ï¼Œç¡®ä¿æ–°å¢å­—æ®µä¸ä¼šç¼ºå¤±
            config = {**DEFAULT_CONFIG, **data}
            config["prompts"] = {**DEFAULT_CONFIG["prompts"], **data.get("prompts", {})}
            return config
        except Exception as e:
            st.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®: {e}")
    return DEFAULT_CONFIG.copy()


def save_config(config):
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=4, ensure_ascii=False)


def is_configured(config):
    """
        æ£€æŸ¥æ˜¯å¦å·²å®Œæˆå¿…è¦é…ç½®ï¼š
        - Finnhub å’Œ Tavily å¿…é¡»å¡«å†™ï¼ˆæ•°æ®æºï¼‰
        - LLM å¹³å°ï¼ˆOpenAI / DeepSeek / é€šä¹‰åƒé—® / è±†åŒ…ï¼‰è‡³å°‘é…ç½®ä¸€ä¸ª API Key
        """
    # å¿…å¡«æ•°æ®æº
    data_required = ["FINNHUB_API_KEY", "TAVILY_API_KEY"]
    if not all(config.get(key, "").strip() != "" for key in data_required):
        return False

    # LLM å¹³å°è‡³å°‘é…ç½®ä¸€ä¸ª
    llm_keys = [
        "OPENAI_API_KEY",
        "DEEPSEEK_API_KEY",
        "QWEN_API_KEY",
        "DOUBAO_API_KEY"
    ]
    if not any(config.get(key, "").strip() != "" for key in llm_keys):
        return False

    return True

# ========================== æµ‹è¯•è¿æ¥å‡½æ•°ï¼ˆæµ‹è¯• Google é¦–é¡µ + æœ¬åœ°åç«¯ï¼‰ ==========================
def test_connections(session):
    results = []
    try:
        resp = session.get("https://www.google.com", timeout=10)
        if resp.status_code == 200:
            results.append(("âœ… å¤–éƒ¨ç½‘ç»œï¼ˆGoogleï¼‰", "è¿æ¥æˆåŠŸï¼Œä»£ç†å·¥ä½œæ­£å¸¸"))
        else:
            results.append(("âš ï¸ å¤–éƒ¨ç½‘ç»œï¼ˆGoogleï¼‰", f"çŠ¶æ€ç  {resp.status_code}"))
    except Exception as e:
        results.append(("âŒ å¤–éƒ¨ç½‘ç»œï¼ˆGoogleï¼‰", f"è¿æ¥å¤±è´¥ï¼š{str(e)}"))

    return results


def get_smart_session(config):
    """
    æ™ºèƒ½ä»£ç†ä¼šè¯ï¼š
    - å¦‚æœç›®æ ‡æ˜¯ 127.0.0.1 æˆ– localhost â†’ ç›´è¿ï¼ˆä¸èµ°ä»£ç†ï¼‰
    - å…¶ä»–æ‰€æœ‰è¯·æ±‚ â†’ èµ°ç”¨æˆ·é…ç½®çš„ä»£ç†
    """
    session = requests.Session()

    if config.get("proxy_enabled", False):
        host = config.get("proxy_host", "").strip()
        port = config.get("proxy_port", "").strip()
        if host and port:
            proxy_url = f"http://{host}:{port}"
            # è®¾ç½®å…¨å±€ä»£ç†
            session.proxies.update({
                "http": proxy_url,
                "https": proxy_url,
            })
            # st.success(f"ä»£ç†å·²å¯ç”¨ï¼š{proxy_url}ï¼ˆå¤–éƒ¨æœåŠ¡èµ°ä»£ç†ï¼Œæœ¬åœ°ç›´è¿ï¼‰")
        else:
            st.warning("ä»£ç†å¯ç”¨ä½†åœ°å€/ç«¯å£ä¸ºç©ºï¼Œå°†ç›´è¿æ‰€æœ‰æœåŠ¡")

        # å…³é”®ï¼šæ·»åŠ  NO_PROXY ç¯å¢ƒå˜é‡ï¼Œç»•è¿‡æœ¬åœ°åœ°å€
        # requests å°Šé‡ NO_PROXY
        import os
        os.environ["NO_PROXY"] = "127.0.0.1,localhost,0.0.0.0"

    else:
        st.sidebar.info("ä»£ç†æœªå¯ç”¨ï¼ˆæ‰€æœ‰æœåŠ¡ç›´è¿ï¼‰")

    return session


def render_settings(user_config):

    with st.expander("ğŸŒ åç«¯æœåŠ¡åœ°å€"):
        api_base = st.text_input("åç«¯ FastAPI æœåŠ¡åœ°å€ï¼ˆAPI_BASEï¼‰", value=user_config.get("API_BASE", "http://127.0.0.1:8000"))

    with st.expander("ğŸŒ ç½‘ç»œä»£ç†è®¾ç½®"):
        proxy_enabled = st.checkbox("å¯ç”¨ç½‘ç»œä»£ç†ï¼ˆä»…å¤–éƒ¨æœåŠ¡ï¼‰", value=user_config.get("proxy_enabled", False))
        proxy_host = st.text_input("ä»£ç†åœ°å€ï¼ˆHostï¼‰", value=user_config.get("proxy_host", "127.0.0.1"))
        proxy_port = st.text_input("ä»£ç†ç«¯å£ï¼ˆPortï¼‰", value=user_config.get("proxy_port", "7890"))

        if st.button("ğŸ§ª æµ‹è¯•ç½‘ç»œè¿æ¥", type="secondary"):
            temp = user_config.copy()
            temp.update({"proxy_enabled": proxy_enabled, "proxy_host": proxy_host, "proxy_port": proxy_port})
            sess = get_smart_session(temp)
            results = test_connections(sess)
            for icon, msg in results:
                if "æˆåŠŸ" in icon or icon == "Google":
                    st.success(f"{icon} {msg}")
                else:
                    st.warning(f"{icon} {msg}")

    with st.expander("ğŸ”‘ API Keys", expanded=not is_configured(user_config)):
        finnhub_key = st.text_input("Finnhub API Key", value=user_config.get("FINNHUB_API_KEY", ""), type="password")
        st.caption("ç”¨é€”ï¼šç”¨äºè·å–å®æ—¶ä¸å†å²å¸‚åœºæ•°æ®ï¼ˆè¡Œæƒ…ã€è´¢åŠ¡ã€æŒ‡æ ‡ç­‰ï¼‰ã€‚ç”³è¯·åœ°å€ï¼šhttps://finnhub.io/")

        tavily_key = st.text_input("Tavily API Key", value=user_config.get("TAVILY_API_KEY", ""), type="password")
        st.caption("ç”¨é€”ï¼šç”¨äºè®¿é—®ç¤¾äº¤åª’ä½“ä¸å¦ç±»æ•°æ®æºï¼ˆæƒ…ç»ªã€è¯é¢˜çƒ­åº¦ç­‰ï¼‰ã€‚ç”³è¯·/æ–‡æ¡£åœ°å€ï¼šè¯·å‚è€ƒ Tavily å®˜æ–¹ç½‘ç«™ï¼ˆä¾‹å¦‚ https://tavily.ai æˆ–æ‚¨çš„æœåŠ¡æä¾›å•†æ§åˆ¶å°ï¼‰ã€‚")

        langsmith_key = st.text_input("LangSmith API Keyï¼ˆå¯é€‰ï¼‰", value=user_config.get("LANGSMITH_API_KEY", ""), type="password")
        st.caption("ç”¨é€”ï¼šç”¨äºå°†æ¨¡å‹è°ƒç”¨ä¸è¿è¡Œæ—¶è¿½è¸ªå‘é€åˆ° LangSmithï¼ˆè°ƒè¯•ã€å¯è§‚æµ‹æ€§ä¸è¿è¡Œè®°å½•ï¼‰ã€‚ç”³è¯·åœ°å€ï¼š https://www.langsmith.com/ æˆ– LangSmith æ§åˆ¶å°ã€‚")

    with st.expander("ğŸ¤– å¤§è¯­è¨€æ¨¡å‹é…ç½®"):
        llm_provider_options = ["ChatGPT(Openai)", "Deepseek", "é€šä¹‰åƒé—®(qwen)", "è±†åŒ…(doubao)"]
        llm_provider = st.selectbox("LLM æä¾›å•† (llm_provider)", options=llm_provider_options, index=llm_provider_options.index(user_config.get("llm_provider", "ChatGPT(Openai)")))
        if llm_provider == "ChatGPT(Openai)":
            openai_api_key = st.text_input("OpenAI API Key", value=user_config.get("OPENAI_API_KEY", ""), type="password")
        elif llm_provider == "Deepseek":
            deepseek_api_key = st.text_input("DeepSeek API Key", value=user_config.get("DEEPSEEK_API_KEY", ""), type="password")
        elif llm_provider == "é€šä¹‰åƒé—®(qwen)":
            qwen_api_key = st.text_input("é€šä¹‰åƒé—® API Key", value=user_config.get("QWEN_API_KEY", ""), type="password")
        elif llm_provider == "è±†åŒ…(doubao)":
            doubao_api_key = st.text_input("è±†åŒ… API Key", value=user_config.get("DOUBAO_API_KEY", ""), type="password")

        deep_think_llm = st.text_input("å¤æ‚æ¨ç†æ¨¡å‹ (deep_think_llm)", value=user_config.get("deep_think_llm", ""))
        quick_think_llm = st.text_input("å¿«é€Ÿå¤„ç†æ¨¡å‹ (quick_think_llm)", value=user_config.get("quick_think_llm", ""))
        backend_url = st.text_input("æ¨¡å‹åŸºåœ°å€ (backend_url)", value=user_config.get("backend_url", ""))

        with st.expander("LLM å¸®åŠ© / æ¨èé…ç½®ï¼ˆç‚¹å‡»æŸ¥çœ‹ï¼‰", expanded=False):
            provider_tips = {
                "ChatGPT(Openai)": {
                    "deep": "gpt-4o",
                    "quick": "gpt-4o-mini",
                    "backend": "https://api.openai.com/v1",
                    "apply": "https://platform.openai.com/account/api-keys",
                    "note": "OpenAI é€‚åˆé«˜è´¨é‡å¤æ‚æ¨ç†ä¸å†³ç­–ï¼›æŒ‰éœ€é€‰æ‹©æ¨¡å‹è§„æ ¼ä»¥å¹³è¡¡æˆæœ¬ä¸æ€§èƒ½ã€‚"
                },
                "Deepseek": {
                    "deep": "deepseek-chat",
                    "quick": "deepseek-coder",
                    "backend": "https://api.deepseek.com/v1",
                    "apply": "https://platform.deepseek.com/api_keys",
                    "note": "Deepseek æä¾›ä½å»¶è¿Ÿçš„ä¼ä¸šæ¨¡å‹ï¼ˆç¤ºä¾‹é“¾æ¥ï¼Œè¯·å‚è€ƒä¾›åº”å•†æ–‡æ¡£ï¼‰ã€‚"
                },
                "é€šä¹‰åƒé—®(qwen)": {
                    "deep": "qwen-7b",
                    "quick": "qwen-mini",
                    "backend": "è¯·å‚è€ƒé˜¿é‡Œäº‘é€šä¹‰åƒé—®æ§åˆ¶å°ï¼ˆé˜¿é‡Œäº‘ï¼‰",
                    "apply": "https://www.aliyun.com/ï¼ˆåœ¨é˜¿é‡Œäº‘æ§åˆ¶å°æœç´¢ â€œé€šä¹‰åƒé—®â€ ä»¥è·å– API Keyï¼‰",
                    "note": "é€šä¹‰åƒé—®ç”±é˜¿é‡Œå·´å·´æä¾›ï¼Œé€‚åˆä¸­æ–‡åœºæ™¯ï¼›è¯·åœ¨é˜¿é‡Œäº‘æ§åˆ¶å°åˆ›å»ºå¹¶æŸ¥çœ‹æ¥å…¥æ–‡æ¡£ã€‚"
                },
                "è±†åŒ…(doubao)": {
                    "deep": "ï¼ˆç¤ºä¾‹æ¨¡å‹ï¼Œä¾æ®ä¾›åº”å•†ï¼‰",
                    "quick": "ï¼ˆç¤ºä¾‹æ¨¡å‹ï¼Œä¾æ®ä¾›åº”å•†ï¼‰",
                    "backend": "è¯·å‚è€ƒæ‚¨çš„è±†åŒ…ä¾›åº”å•†æˆ–ç§æœ‰éƒ¨ç½²æ–‡æ¡£",
                    "apply": "è¯·å’¨è¯¢è±†åŒ…ä¾›åº”å•†æˆ–æŸ¥çœ‹å…¶å¼€å‘è€…æ§åˆ¶å°/æ–‡æ¡£",
                    "note": "â€œè±†åŒ…â€ åœ¨æ­¤ä½œä¸ºç¤ºä¾‹å ä½ï¼ˆä¸åŒæœºæ„å®ç°ä¸åŒï¼‰ã€‚å¦‚éœ€æˆ‘æŠŠå…·ä½“ä¾›åº”å•†é“¾æ¥æˆ–é»˜è®¤æ¨¡å‹å†™å…¥é…ç½®ï¼Œè¯·æä¾›å‡†ç¡® URL æˆ–è¯´æ˜ã€‚"
                }
            }
            tip = provider_tips.get(llm_provider, {})
            if tip:
                st.markdown(f"**å»ºè®®å¤æ‚æ¨ç†æ¨¡å‹:** {tip.get('deep')}  ")
                st.markdown(f"**å»ºè®®å¿«é€Ÿå¤„ç†æ¨¡å‹:** {tip.get('quick')}  ")
                st.markdown(f"**å»ºè®®æ¨¡å‹åŸºåœ°å€:** {tip.get('backend')}  ")
                st.markdown(f"**API Key ç”³è¯·/æ–‡æ¡£:** [{tip.get('apply')}]({tip.get('apply')})  ")
                st.caption(tip.get('note'))
            else:
                st.write("è¯·å‚è€ƒæ‰€é€‰æä¾›å•†çš„å®˜æ–¹æ–‡æ¡£ä»¥è·å–æ¨èæ¨¡å‹ä¸ç”³è¯·é“¾æ¥ã€‚")

 

    with st.expander("ğŸ› ï¸ ç³»ç»Ÿå‚æ•°"):
        max_debate = st.slider("å¤šç©ºè¾©è®ºè½®æ•°", 1, 5, user_config.get("max_debate_rounds", 2))
        max_risk = st.slider("é£æ§è¾©è®ºè½®æ•°", 1, 3, user_config.get("max_risk_discuss_rounds", 1))
        max_recur = st.number_input("æœ€å¤§é€’å½’é™åˆ¶", 50, 500, user_config.get("max_recur_limit", 100))
        online_tools = st.checkbox("å¯ç”¨åœ¨çº¿å·¥å…·", value=user_config.get("online_tools", True))

    with st.expander("âœï¸ è‡ªå®šä¹‰æç¤ºè¯"):
        prompts = user_config.get("prompts", {}).copy()
        for key, label in [("bull", "å¤šå¤´åˆ†æå‘˜"), ("bear", "ç©ºå¤´åˆ†æå‘˜"), ("risky", "æ¿€è¿›é£æ§ç ”ç©¶å‘˜"), ("safe", "ç¨³å¥é£æ§ç ”ç©¶å‘˜"), ("neutral", "å¹³è¡¡é£æ§ç ”ç©¶å‘˜"), ("market_analyst", "å¸‚åœºåˆ†æå¸ˆ"), ("social_analyst", "ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ"), ("news_analyst", "æ–°é—»åˆ†æå¸ˆ"), ("fundamentals_analyst", "åŸºæœ¬é¢åˆ†æå¸ˆ")]:
            prompts[key] = st.text_area(f"{label}æç¤ºè¯", value=prompts.get(key, ""), height=100)

    if st.button("ğŸ’¾ ä¿å­˜æ‰€æœ‰è®¾ç½®", type="primary", use_container_width=True):
        new_config = user_config.copy()
        new_config.update({
            "FINNHUB_API_KEY": finnhub_key.strip(),
            "TAVILY_API_KEY": tavily_key.strip(),
            "LANGSMITH_API_KEY": langsmith_key.strip(),
            "API_BASE": api_base.strip().rstrip("/"),
            "llm_provider": llm_provider,
            "deep_think_llm": deep_think_llm.strip(),
            "quick_think_llm": quick_think_llm.strip(),
            "backend_url": backend_url.strip().rstrip("/"),
            "proxy_enabled": proxy_enabled,
            "proxy_host": proxy_host.strip(),
            "proxy_port": proxy_port.strip(),
            "max_debate_rounds": max_debate,
            "max_risk_discuss_rounds": max_risk,
            "max_recur_limit": max_recur,
            "online_tools": online_tools,
            "prompts": prompts
        })

        # provider-specific keys
        if llm_provider == "ChatGPT(Openai)":
            new_config["OPENAI_API_KEY"] = openai_api_key.strip()
        elif llm_provider == "Deepseek":
            new_config["DEEPSEEK_API_KEY"] = deepseek_api_key.strip()
        elif llm_provider == "é€šä¹‰åƒé—®(qwen)":
            new_config["QWEN_API_KEY"] = qwen_api_key.strip()
        elif llm_provider == "è±†åŒ…(doubao)":
            new_config["DOUBAO_API_KEY"] = doubao_api_key.strip()

        save_config(new_config)
        st.success("âœ… è®¾ç½®å·²ä¿å­˜,æ­£åœ¨åº”ç”¨æ–°é…ç½®...")
        st.balloons()
        time.sleep(1)
        st.experimental_rerun()
