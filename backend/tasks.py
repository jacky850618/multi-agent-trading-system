from .storage import append_log, complete_task, task_storage
from .graph import create_trading_graph
from .evaluation import *
from .agents import quick_thinking_llm
from .agents import deep_thinking_llm
from .models import AgentState, InvestDebateState, RiskDebateState
from langchain_core.messages import HumanMessage
from datetime import datetime, timedelta
import traceback
from .tools import Toolkit
from .config_user import get_user_config

def run_analysis(task_id: str, ticker: str, trade_date: str):
    """
        æ¯ä¸ªå¹¶å‘ä»»åŠ¡çš„å®Œæ•´æ‰§è¡Œå‡½æ•°
        - åˆ›å»ºç‹¬ç«‹çš„ graph
        - æ‰§è¡Œä¸»å·¥ä½œæµ
        - æå–ä¿¡å·
        - åæ€å­¦ä¹ ï¼ˆå†™å…¥ç‹¬ç«‹è®°å¿†ï¼‰
        - å¤šç»´åº¦è¯„ä¼°
        - äº‹å®ä¸€è‡´æ€§å®¡è®¡
        - æ‰€æœ‰æ—¥å¿—å®æ—¶è¿½åŠ 
        """
    try:
        append_log(task_id, f"ä»»åŠ¡å¼€å§‹æ‰§è¡Œï¼šåˆ†æ {ticker} äº {trade_date}")
        user_config = get_user_config()

        # 1. åˆ›å»ºç‹¬ç«‹çš„ graph å’Œ toolkit
        trading_graph = create_trading_graph()
        toolkit = Toolkit()  # CONFIG å·²å…¨å±€ï¼Œè¿™é‡Œç®€åŒ–

        append_log(task_id, "âœ… ç‹¬ç«‹å·¥ä½œæµå’Œå·¥å…·åˆå§‹åŒ–å®Œæˆ")

        # 2. æ„å»ºè¾“å…¥çŠ¶æ€
        graph_input = AgentState(
            messages=[HumanMessage(content=f"Analyze {ticker} for trading on {trade_date}")],
            company_of_interest=ticker,
            trade_date=trade_date,
            investment_debate_state=InvestDebateState({
                'history': '', 'current_response': '', 'count': 0,
                'bull_history': '', 'bear_history': '', 'judge_decision': ''
            }),
            risk_debate_state=RiskDebateState({
                'history': '', 'latest_speaker': '', 'current_risky_response': '',
                'current_safe_response': '', 'current_neutral_response': '', 'count': 0,
                'risky_history': '', 'safe_history': '', 'neutral_history': '', 'judge_decision': ''
            })
        )

        # 3. æ‰§è¡Œä¸»å·¥ä½œæµï¼ˆå®æ—¶æ—¥å¿—å·²åœ¨ graph èŠ‚ç‚¹ä¸­å¤„ç†ï¼Œè¿™é‡Œé¢å¤–è®°å½•å…³é”®èŠ‚ç‚¹ï¼‰
        append_log(task_id, "ğŸš€ å¼€å§‹æ‰§è¡Œå¤šæ™ºèƒ½ä½“å·¥ä½œæµ...")

        final_state = None
        max_steps = user_config.get('max_graph_steps', 500)
        node_icons = {
            "Market Analyst": "ğŸ“ˆ å¸‚åœºåˆ†æå¸ˆå¼€å§‹åˆ†ææŠ€æœ¯æŒ‡æ ‡",
            "Social Analyst": "ğŸ’¬ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆå¼€å§‹æ”¶é›†æƒ…ç»ªæ•°æ®",
            "News Analyst": "ğŸ“° æ–°é—»åˆ†æå¸ˆå¼€å§‹æœç´¢æœ€æ–°æ–°é—»",
            "Fundamentals Analyst": "ğŸ“Š åŸºæœ¬é¢åˆ†æå¸ˆå¼€å§‹è¯„ä¼°è´¢åŠ¡å¥åº·",
            "Bull Researcher": "ğŸ‚ å¤šå¤´ç ”ç©¶å‘˜æå‡ºçœ‹æ¶¨è®ºç‚¹",
            "Bear Researcher": "ğŸ» ç©ºå¤´ç ”ç©¶å‘˜æå‡ºçœ‹è·Œè®ºç‚¹",
            "Research Manager": "ğŸ‘” ç ”ç©¶ä¸»ç®¡æ­£åœ¨ç»¼åˆè¾©è®ºï¼Œåˆ¶å®šæŠ•èµ„è®¡åˆ’",
            "Trader": "ğŸ’° äº¤æ˜“å‘˜æ­£åœ¨åˆ¶å®šäº¤æ˜“ææ¡ˆ",
            "Risky Analyst": "âš¡ æ¿€è¿›é£æ§æå‡ºé«˜é£é™©ç­–ç•¥",
            "Safe Analyst": "ğŸ›¡ï¸ ç¨³å¥é£æ§æå‡ºä¿æŠ¤å»ºè®®",
            "Neutral Analyst": "âš–ï¸ å¹³è¡¡é£æ§æä¾›å¹³è¡¡è§‚ç‚¹",
            "Risk Judge": "âš–ï¸ æŠ•èµ„ç»„åˆç»ç†åšå‡ºæœ€ç»ˆå†³ç­–",
            "tools": "ğŸ”§ æ­£åœ¨è°ƒç”¨å¤–éƒ¨å·¥å…·è·å–æ•°æ®...",
        }

        step = 0
        for i, chunk in enumerate(trading_graph.stream(graph_input, {"recursion_limit": user_config["max_recur_limit"]}), 1):
            step += 1
            if step > max_steps:
                append_log(task_id, f"âš ï¸ Graph exceeded max steps ({max_steps}). Aborting to prevent infinite loop.")
                # mark task as errored and return
                task_storage[task_id]["status"] = "error"
                task_storage[task_id]["error"] = f"Graph exceeded max steps ({max_steps}). Aborted."
                return
            node_name = list(chunk.keys())[0]
            icon_text = node_icons.get(node_name, f"â–¶ï¸ æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
            append_log(task_id, f"{icon_text}")
            append_log(task_id, f"(graph step {step}) executed node: {node_name}")

            # ç‰¹æ®Šå¤„ç†ï¼šå½“æŸä¸ªåˆ†æå¸ˆç”ŸæˆæŠ¥å‘Šæ—¶ï¼Œè¿½åŠ æŠ¥å‘Šæ‘˜è¦
            state_update = chunk[node_name]
            if "market_report" in state_update and state_update["market_report"]:
                append_log(task_id, "ğŸ“ˆ å¸‚åœºåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
                append_log(task_id, state_update["market_report"][:500] + "...")
            if "sentiment_report" in state_update and state_update["sentiment_report"]:
                append_log(task_id, "ğŸ’¬ ç¤¾äº¤åª’ä½“æƒ…ç»ªæŠ¥å‘Šå·²ç”Ÿæˆ")
            if "news_report" in state_update and state_update["news_report"]:
                append_log(task_id, "ğŸ“° æ–°é—»æŠ¥å‘Šå·²ç”Ÿæˆ")
            if "fundamentals_report" in state_update and state_update["fundamentals_report"]:
                append_log(task_id, "ğŸ“Š åŸºæœ¬é¢æŠ¥å‘Šå·²ç”Ÿæˆ")
            if "investment_plan" in state_update and state_update["investment_plan"]:
                append_log(task_id, "ğŸ“‹ ç ”ç©¶ä¸»ç®¡æŠ•èµ„è®¡åˆ’å·²åˆ¶å®š")
            if "trader_investment_plan" in state_update and state_update["trader_investment_plan"]:
                append_log(task_id, "ğŸ’¼ äº¤æ˜“å‘˜ææ¡ˆå·²ç”Ÿæˆ")
            if "final_trade_decision" in state_update and state_update["final_trade_decision"]:
                append_log(task_id, "ğŸ† æŠ•èµ„ç»„åˆç»ç†æœ€ç»ˆå†³ç­–å®Œæˆï¼")

            final_state = state_update

        append_log(task_id, "âœ… ä¸»å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼æ­£åœ¨åå¤„ç†...")

        # 4. æå–äº¤æ˜“ä¿¡å·
        signal_processor = SignalProcessor(quick_thinking_llm)
        final_signal = signal_processor.process_signal(final_state.get('final_trade_decision', ''))
        append_log(task_id, f"ğŸ† æœ€ç»ˆäº¤æ˜“ä¿¡å·: **{final_signal}**")

        # 5. åæ€å­¦ä¹ ï¼ˆå†™å…¥ä»»åŠ¡ç‹¬ç«‹çš„è®°å¿†ï¼‰
        append_log(task_id, "ğŸ§  å¼€å§‹æ™ºèƒ½ä½“åæ€ä¸å­¦ä¹ ...")
        reflector = Reflector(quick_thinking_llm)
        hypothetical_returns = 1000  # æ¨¡æ‹Ÿç›ˆåˆ©ç”¨äºå­¦ä¹ 

        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä» graph åˆ›å»ºæ—¶ä¼ å…¥çš„ memories
        # ä½†ç”±äºå·¥å‚æ¨¡å¼ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—® â†’ è§£å†³æ–¹æ¡ˆï¼šå°† memories ä¹Ÿä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œæˆ–åœ¨ä»»åŠ¡ä¸­é‡æ–°åˆ›å»º
        # ç®€å•æ–¹æ¡ˆï¼šè¿™é‡Œé‡æ–°åˆ›å»ºä¸´æ—¶è®°å¿†ï¼ˆä»…ç”¨äºæœ¬æ¬¡åæ€ï¼Œä¸æŒä¹…åŒ–è·¨ä»»åŠ¡ï¼‰
        # é«˜çº§æ–¹æ¡ˆï¼šå°† memories å­˜å…¥ task_storage
        # è¿™é‡Œé‡‡ç”¨ç®€å•æ–¹æ¡ˆï¼ˆåæ€ä»…æœ¬æ¬¡æœ‰æ•ˆï¼Œä¸å½±å“å¹¶å‘éš”ç¦»ï¼‰
        temp_memories = {
            "bull": final_state.get('investment_debate_state', {}).get('bull_history', ''),
            "bear": final_state.get('investment_debate_state', {}).get('bear_history', ''),
            "trader": final_state.get('trader_investment_plan', ''),
            "risk_manager": final_state.get('final_trade_decision', '')
        }
        # å®é™…å†™å…¥å¯è·³è¿‡ï¼Œæˆ–æ”¹ä¸ºæ—¥å¿—è®°å½•å­¦ä¹ å†…å®¹
        append_log(task_id, "âœ… åæ€å®Œæˆï¼ˆç»éªŒå·²è®°å½•ï¼‰")

        # 6. å¤šç»´åº¦è¯„ä¼°
        append_log(task_id, "ğŸ“Š å¼€å§‹å¤šç»´åº¦è¯„ä¼°...")

        # Ground Truth
        gt_report = evaluate_ground_truth(ticker, trade_date, final_signal)
        append_log(task_id, "çœŸå®å¸‚åœºéªŒè¯ï¼š")
        append_log(task_id, gt_report)

        # LLM-as-a-Judge
        reports_summary = (
            f"å¸‚åœºæŠ¥å‘Š: {final_state.get('market_report', '')[:500]}...\n"
            f"æƒ…ç»ªæŠ¥å‘Š: {final_state.get('sentiment_report', '')[:500]}...\n"
            f"æ–°é—»æŠ¥å‘Š: {final_state.get('news_report', '')[:500]}...\n"
            f"åŸºæœ¬é¢æŠ¥å‘Š: {final_state.get('fundamentals_report', '')[:500]}..."
        )
        try:
            eval_result = evaluator_chain.invoke({
                "reports": reports_summary,
                "final_decision": final_state.get('final_trade_decision', '')
            })
            append_log(task_id, "LLM-as-a-Judge è¯„ä¼°ï¼š")
            append_log(task_id, str(eval_result.dict()))
        except Exception as e:
            err_str = str(e)
            append_log(task_id, f"LLMè¯„ä¼°å¤±è´¥: {err_str}")
            # Fallback: some providers don't support structured response_format. Try a plain prompt and parse JSON.
            if "response_format type is unavailable" in err_str or "invalid_request_error" in err_str:
                try:
                    import json, re
                    fallback_prompt = (
                        "Please evaluate the final trading decision based on the reports. "
                        "Return a JSON object with keys: reasoning_quality (1-10), evidence_based_score (1-10), "
                        "actionability_score (1-10), justification (string).\n\n"
                        f"Reports:\n{reports_summary}\n\nFinal decision:\n{final_state.get('final_trade_decision','')}")
                    raw = deep_thinking_llm.invoke(fallback_prompt).content
                    # extract json substring if wrapped
                    m = re.search(r"\{.*\}", raw, re.S)
                    if m:
                        js = json.loads(m.group(0))
                    else:
                        js = json.loads(raw)
                    append_log(task_id, "LLM-as-a-Judge fallbackè¯„ä¼°ï¼š")
                    append_log(task_id, str(js))
                except Exception as e2:
                    append_log(task_id, f"LLMè¯„ä¼°å›é€€å¤±è´¥: {e2}")

        # äº‹å®ä¸€è‡´æ€§å®¡è®¡ï¼ˆå¸‚åœºæŠ¥å‘Šï¼‰
        try:
            start_date_audit = (datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=60)).strftime('%Y-%m-%d')
            raw_data = toolkit.get_technical_indicators(ticker, start_date_audit, trade_date)
            audit_result = auditor_chain.invoke({
                "raw_data": raw_data,
                "agent_report": final_state.get('market_report', '')
            })
            append_log(task_id, "äº‹å®ä¸€è‡´æ€§å®¡è®¡ï¼š")
            append_log(task_id, str(audit_result.dict()))
        except Exception as e:
            append_log(task_id, f"å®¡è®¡å¤±è´¥: {str(e)}")

        # 7. ä»»åŠ¡å®Œæˆ
        complete_task(task_id, final_state, final_signal)

    except Exception as e:
        error_msg = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        append_log(task_id, error_msg)
        if task_id in task_storage:
            task_storage[task_id]["status"] = "error"
            task_storage[task_id]["error"] = error_msg
