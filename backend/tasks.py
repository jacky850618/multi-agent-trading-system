from .storage import append_log, complete_task, task_storage
from .graph import create_trading_graph
from evaluation import *
from agents import quick_thinking_llm
from models import AgentState, InvestDebateState, RiskDebateState
from langchain_core.messages import HumanMessage
import datetime
import traceback
from tools import Toolkit
from backend.config_user import get_user_config

def run_analysis(task_id: str, ticker: str, trade_date: str):
    """
        æ¯ä¸ªå¹¶å‘ä»»åŠ¡çš„å®Œæ•´æ‰§è¡Œå‡½æ•°
        - åˆ›å»ºç‹¬ç«‹çš„ graph
        - æ‰§è¡Œä¸»å·¥ä½œæµ
        - æå–ä¿¡å·
        - åæ€å­¦ä¹ ï¼ˆå†™å…¥ç‹¬ç«‹è®°å¿†ï¼‰
        - å¤šç»´åº¦è¯„ä¼°
        - äº‹å®ä¸€è‡´æ€§å®¡è®¡
        - æ‰€æœ‰æ—¥å¿—å®æ—¶è¿½åŠ 
        """
    try:
        append_log(task_id, f"ä»»åŠ¡å¼€å§‹ï¼šåˆ†æ {ticker} äº {trade_date}")
        user_config = get_user_config()

        # 1. åˆ›å»ºç‹¬ç«‹çš„ graph å’Œ toolkit
        trading_graph = create_trading_graph()
        toolkit = Toolkit({})  # CONFIG å·²å…¨å±€ï¼Œè¿™é‡Œç®€åŒ–

        append_log(task_id, "âœ… ç‹¬ç«‹å·¥ä½œæµå’Œå·¥å…·åˆå§‹åŒ–å®Œæˆ")

        # 2. æ„å»ºè¾“å…¥çŠ¶æ€
        graph_input = AgentState(
            messages=[HumanMessage(content=f"Analyze {ticker} for trading on {trade_date}")],
            company_of_interest=ticker,
            trade_date=trade_date,
            investment_debate_state=InvestDebateState({
                'history': '', 'current_response': '', 'count': 0,
                'bull_history': '', 'bear_history': '', 'judge_decision': ''
            }),
            risk_debate_state=RiskDebateState({
                'history': '', 'latest_speaker': '', 'current_risky_response': '',
                'current_safe_response': '', 'current_neutral_response': '', 'count': 0,
                'risky_history': '', 'safe_history': '', 'neutral_history': '', 'judge_decision': ''
            })
        )

        # 3. æ‰§è¡Œä¸»å·¥ä½œæµï¼ˆå®æ—¶æ—¥å¿—å·²åœ¨ graph èŠ‚ç‚¹ä¸­å¤„ç†ï¼Œè¿™é‡Œé¢å¤–è®°å½•å…³é”®èŠ‚ç‚¹ï¼‰
        append_log(task_id, "ğŸš€ å¼€å§‹æ‰§è¡Œå¤šä»£ç†å·¥ä½œæµ...")

        final_state = None
        node_icons = {
            "Market Analyst": "ğŸ“ˆ å¸‚åœºåˆ†æå¸ˆ",
            "Social Analyst": "ğŸ’¬ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ",
            "News Analyst": "ğŸ“° æ–°é—»åˆ†æå¸ˆ",
            "Fundamentals Analyst": "ğŸ“Š åŸºæœ¬é¢åˆ†æå¸ˆ",
            "Bull Researcher": "ğŸ‚ å¤šå¤´ç ”ç©¶å‘˜",
            "Bear Researcher": "ğŸ» ç©ºå¤´ç ”ç©¶å‘˜",
            "Research Manager": "ğŸ‘” ç ”ç©¶ä¸»ç®¡",
            "Trader": "ğŸ’° äº¤æ˜“å‘˜",
            "Risky Analyst": "âš¡ æ¿€è¿›é£æ§",
            "Safe Analyst": "ğŸ›¡ï¸ ä¿å®ˆé£æ§",
            "Neutral Analyst": "âš–ï¸ ä¸­ç«‹é£æ§",
            "Risk Judge": "âš–ï¸ æœ€ç»ˆå†³ç­–",
            "tools": "ğŸ”§ å·¥å…·è°ƒç”¨",
        }

        for i, chunk in enumerate(trading_graph.stream(graph_input, {"recursion_limit": user_config["max_recur_limit"]}), 1):
            node_name = list(chunk.keys())[0]
            icon = node_icons.get(node_name, "â–¶ï¸")
            append_log(task_id, f"{icon} [{i:2d}] {node_name}")
            final_state = chunk[node_name]

        append_log(task_id, "âœ… ä¸»å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼æ­£åœ¨åå¤„ç†...")

        # 4. æå–äº¤æ˜“ä¿¡å·
        signal_processor = SignalProcessor(quick_thinking_llm)
        final_signal = signal_processor.process_signal(final_state.get('final_trade_decision', ''))
        append_log(task_id, f"ğŸ† æœ€ç»ˆäº¤æ˜“ä¿¡å·: **{final_signal}**")

        # 5. åæ€å­¦ä¹ ï¼ˆå†™å…¥ä»»åŠ¡ç‹¬ç«‹çš„è®°å¿†ï¼‰
        append_log(task_id, "ğŸ§  å¼€å§‹æ™ºèƒ½ä½“åæ€ä¸å­¦ä¹ ...")
        reflector = Reflector(quick_thinking_llm)
        hypothetical_returns = 1000  # æ¨¡æ‹Ÿç›ˆåˆ©ç”¨äºå­¦ä¹ 

        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä» graph åˆ›å»ºæ—¶ä¼ å…¥çš„ memories
        # ä½†ç”±äºå·¥å‚æ¨¡å¼ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—® â†’ è§£å†³æ–¹æ¡ˆï¼šå°† memories ä¹Ÿä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œæˆ–åœ¨ä»»åŠ¡ä¸­é‡æ–°åˆ›å»º
        # ç®€å•æ–¹æ¡ˆï¼šè¿™é‡Œé‡æ–°åˆ›å»ºä¸´æ—¶è®°å¿†ï¼ˆä»…ç”¨äºæœ¬æ¬¡åæ€ï¼Œä¸æŒä¹…åŒ–è·¨ä»»åŠ¡ï¼‰
        # é«˜çº§æ–¹æ¡ˆï¼šå°† memories å­˜å…¥ task_storage
        # è¿™é‡Œé‡‡ç”¨ç®€å•æ–¹æ¡ˆï¼ˆåæ€ä»…æœ¬æ¬¡æœ‰æ•ˆï¼Œä¸å½±å“å¹¶å‘éš”ç¦»ï¼‰
        temp_memories = {
            "bull": final_state.get('investment_debate_state', {}).get('bull_history', ''),
            "bear": final_state.get('investment_debate_state', {}).get('bear_history', ''),
            "trader": final_state.get('trader_investment_plan', ''),
            "risk_manager": final_state.get('final_trade_decision', '')
        }
        # å®é™…å†™å…¥å¯è·³è¿‡ï¼Œæˆ–æ”¹ä¸ºæ—¥å¿—è®°å½•å­¦ä¹ å†…å®¹
        append_log(task_id, "âœ… åæ€å®Œæˆï¼ˆç»éªŒå·²è®°å½•ï¼‰")

        # 6. å¤šç»´åº¦è¯„ä¼°
        append_log(task_id, "ğŸ“Š å¼€å§‹å¤šç»´åº¦è¯„ä¼°...")

        # Ground Truth
        gt_report = evaluate_ground_truth(ticker, trade_date, final_signal)
        append_log(task_id, "çœŸå®å¸‚åœºéªŒè¯ï¼š")
        append_log(task_id, gt_report)

        # LLM-as-a-Judge
        reports_summary = (
            f"å¸‚åœºæŠ¥å‘Š: {final_state.get('market_report', '')[:500]}...\n"
            f"æƒ…ç»ªæŠ¥å‘Š: {final_state.get('sentiment_report', '')[:500]}...\n"
            f"æ–°é—»æŠ¥å‘Š: {final_state.get('news_report', '')[:500]}...\n"
            f"åŸºæœ¬é¢æŠ¥å‘Š: {final_state.get('fundamentals_report', '')[:500]}..."
        )
        try:
            eval_result = evaluator_chain.invoke({
                "reports": reports_summary,
                "final_decision": final_state.get('final_trade_decision', '')
            })
            append_log(task_id, "LLM-as-a-Judge è¯„ä¼°ï¼š")
            append_log(task_id, str(eval_result.dict()))
        except Exception as e:
            append_log(task_id, f"LLMè¯„ä¼°å¤±è´¥: {str(e)}")

        # äº‹å®ä¸€è‡´æ€§å®¡è®¡ï¼ˆå¸‚åœºæŠ¥å‘Šï¼‰
        try:
            start_date_audit = (datetime.strptime(trade_date, "%Y-%m-%d") - timedelta(days=60)).strftime('%Y-%m-%d')
            raw_data = toolkit.get_technical_indicators(ticker, start_date_audit, trade_date)
            audit_result = auditor_chain.invoke({
                "raw_data": raw_data,
                "agent_report": final_state.get('market_report', '')
            })
            append_log(task_id, "äº‹å®ä¸€è‡´æ€§å®¡è®¡ï¼š")
            append_log(task_id, str(audit_result.dict()))
        except Exception as e:
            append_log(task_id, f"å®¡è®¡å¤±è´¥: {str(e)}")

        # 7. ä»»åŠ¡å®Œæˆ
        complete_task(task_id, final_state, final_signal)

    except Exception as e:
        error_msg = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        append_log(task_id, error_msg)
        if task_id in task_storage:
            task_storage[task_id]["status"] = "error"
            task_storage[task_id]["error"] = error_msg
